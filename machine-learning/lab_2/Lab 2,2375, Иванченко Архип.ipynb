{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23473369",
   "metadata": {},
   "source": [
    "# Лабораторная работа №2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f12fc9c",
   "metadata": {},
   "source": [
    "Будем использовать тот же датасет, что мы использовали в прошлой работе"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986d01c1",
   "metadata": {},
   "source": [
    "Дла начала, добавим в наш исходный датасет новый атрибут: Beats Per Track (BPT) - количество тактов на протяжении всего трека. BPT = BPM * (Длительность трека в минутах)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52f6554",
   "metadata": {},
   "source": [
    "Сперва считаем наш датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ff795be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import seaborn\n",
    "\n",
    "data = pd.read_csv(\"../dataset/spotify.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7a23b6",
   "metadata": {},
   "source": [
    "Теперь добавим новый атрибут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f881bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpt_list = []\n",
    "for i, row in data.iterrows():\n",
    "    minutes = row['duration_ms'] / (1000 * 60)\n",
    "    bpt = minutes * row['tempo']\n",
    "    bpt_list.append(bpt)\n",
    "\n",
    "bpt = pd.Series(bpt_list)\n",
    "data.insert(0, \"bpt\", bpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ac23e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10078 entries, 0 to 10077\n",
      "Data columns (total 17 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   bpt               9528 non-null   float64\n",
      " 1   trackName         10078 non-null  object \n",
      " 2   artistName        10078 non-null  object \n",
      " 3   genre             8578 non-null   object \n",
      " 4   danceability      9528 non-null   float64\n",
      " 5   energy            9528 non-null   float64\n",
      " 6   key               9528 non-null   float64\n",
      " 7   loudness          9528 non-null   float64\n",
      " 8   mode              9528 non-null   float64\n",
      " 9   speechiness       9528 non-null   float64\n",
      " 10  acousticness      9528 non-null   float64\n",
      " 11  instrumentalness  9528 non-null   float64\n",
      " 12  liveness          9528 non-null   float64\n",
      " 13  valence           9528 non-null   float64\n",
      " 14  tempo             9528 non-null   float64\n",
      " 15  duration_ms       9528 non-null   float64\n",
      " 16  time_signature    9528 non-null   float64\n",
      "dtypes: float64(14), object(3)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# сводка по данным\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b542e88",
   "metadata": {},
   "source": [
    "### \"Причешем\" наш датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b652b02a",
   "metadata": {},
   "source": [
    "Для построения графиков зависимостей атрибутов, сперва удалим все данные с ненужной информацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61533c5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(['trackName', 'artistName', 'genre', 'mode', \"key\", \"time_signature\", \"duration_ms\", \"time_signature\"], axis=\"columns\")\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26133764",
   "metadata": {},
   "source": [
    "Сразу же нормализуем оставшиеся значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e845157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "normalizer = MinMaxScaler()\n",
    "normed_data = normalizer.fit_transform(data)\n",
    "data = pd.DataFrame(normed_data, columns=data.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449d639a",
   "metadata": {},
   "source": [
    "Отбросим данные с выбросами по Z-Score (Z-Score < 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "665748f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9528 entries, 0 to 9527\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   bpt               9528 non-null   float64\n",
      " 1   danceability      9528 non-null   float64\n",
      " 2   energy            9528 non-null   float64\n",
      " 3   loudness          9528 non-null   float64\n",
      " 4   speechiness       9528 non-null   float64\n",
      " 5   acousticness      9528 non-null   float64\n",
      " 6   instrumentalness  9528 non-null   float64\n",
      " 7   liveness          9528 non-null   float64\n",
      " 8   valence           9528 non-null   float64\n",
      " 9   tempo             9528 non-null   float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 744.5 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9528 entries, 0 to 9527\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   bpt               9472 non-null   float64\n",
      " 1   danceability      9456 non-null   float64\n",
      " 2   energy            9528 non-null   float64\n",
      " 3   loudness          9314 non-null   float64\n",
      " 4   speechiness       9280 non-null   float64\n",
      " 5   acousticness      9528 non-null   float64\n",
      " 6   instrumentalness  9528 non-null   float64\n",
      " 7   liveness          9288 non-null   float64\n",
      " 8   valence           9528 non-null   float64\n",
      " 9   tempo             9512 non-null   float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 744.5 KB\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "data.info()\n",
    "for attr in data:\n",
    "    attr_zscore = np.abs(stats.zscore(data[attr]))\n",
    "    data[attr] = data[attr][attr_zscore<3]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "603663e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9528 entries, 0 to 9527\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   bpt               9528 non-null   float64\n",
      " 1   danceability      9528 non-null   float64\n",
      " 2   energy            9528 non-null   float64\n",
      " 3   loudness          9528 non-null   float64\n",
      " 4   speechiness       9528 non-null   float64\n",
      " 5   acousticness      9528 non-null   float64\n",
      " 6   instrumentalness  9528 non-null   float64\n",
      " 7   liveness          9528 non-null   float64\n",
      " 8   valence           9528 non-null   float64\n",
      " 9   tempo             9528 non-null   float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 744.5 KB\n"
     ]
    }
   ],
   "source": [
    "for attr in data:\n",
    "    data[attr] = data[attr].fillna(0.5)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d358da",
   "metadata": {},
   "source": [
    "### Построим матрциу графиков рассеивания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dc3d90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scatter = pd.plotting.scatter_matrix(\n",
    "    data,\n",
    "    figsize=(23, 23)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c17f0",
   "metadata": {},
   "source": [
    "По данным графикам тяжело разглядеть какие-либо кластеры"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546b8e22",
   "metadata": {},
   "source": [
    "## Попробуем применить метод К-средних к нашему датасету"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e90e90",
   "metadata": {},
   "source": [
    "Так как датасет 10-мерный, его кластеры будет тяжело визулизировать. Поставим задачу снизить размерность при помощи PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be09a01",
   "metadata": {},
   "source": [
    "### Снижение размерности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d079f2f7",
   "metadata": {},
   "source": [
    "Предварительно стандартизуем наши данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef4917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "data = pd.DataFrame(scaled_data, columns=data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d496bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit_transform(data)\n",
    "\n",
    "disp = pca.explained_variance_ratio_\n",
    "PC_numbers = np.arange(pca.n_components_) + 1\n",
    "\n",
    "plt.plot(PC_numbers, disp, \"go-\")\n",
    "plt.xlabel(\"Количество компонент\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae364f3c",
   "metadata": {},
   "source": [
    "Выберем число главных компонент = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f875ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(data)\n",
    "\n",
    "pca_data = pd.DataFrame(pca_data, columns = ['PC1', 'PC2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306559e3",
   "metadata": {},
   "source": [
    "### Применим алгоритм K-средних для разного числа кластеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e31c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# максимальное число кластеров, которых хотим получить\n",
    "max_clusters = 6\n",
    "\n",
    "for i in range(2, max_clusters + 1):\n",
    "    kmeans = KMeans(n_clusters=i)\n",
    "    kmeans.fit(pca_data)\n",
    "\n",
    "    centers = kmeans.cluster_centers_\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    data_plot = pca_data.to_numpy()\n",
    "    \n",
    "    labels_map = dict()\n",
    "    \n",
    "    for i, el in enumerate(labels):\n",
    "        v = labels_map.get(el)\n",
    "        if v is not None and len(v) >= 0:\n",
    "            labels_map[el].append(data_plot[i])\n",
    "        else:\n",
    "            labels_map[el] = []\n",
    "\n",
    "\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    \n",
    "    \n",
    "    for label in labels_map.keys():\n",
    "        x = []\n",
    "        y = []\n",
    "        for coord in labels_map[label]:\n",
    "            x.append(coord[0])\n",
    "            y.append(coord[1])\n",
    "        plt.scatter(x, y)\n",
    "            \n",
    "\n",
    "    plt.scatter(centers[:, 0], centers[:, 1], c='black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0cbaea",
   "metadata": {},
   "source": [
    "# Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0692722a",
   "metadata": {},
   "source": [
    "В ходе работы мы добавили новый аттрибут в существующий датасет, затем этот датасет был обработан (выявлены выбросы, проведена нормализация и стандартизация).\n",
    "\n",
    "Затем мы построили матрицу графиков рассеивания, методом главных компонент уменьшили размерность датасета и посмотрели, каким образом этот уменьшенный датасет будет разбиваться на произольное число кластеров методом К-средних"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
